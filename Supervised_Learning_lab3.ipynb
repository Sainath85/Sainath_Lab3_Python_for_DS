{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbd582c",
   "metadata": {
    "id": "fcbd582c"
   },
   "source": [
    "## Learning Outcomes\n",
    "- Exploratory data analysis & preparing the data for model building. \n",
    "- Machine Learning - Supervised Learning Classification\n",
    "  - Logistic Regression\n",
    "  - Naive bayes Classifier\n",
    "  - KNN Classifier\n",
    "  - Decision Tree Classifier\n",
    "  - Random Forest Classifier\n",
    "  - Ensemble methods\n",
    "- Training and making predictions using different classification models.\n",
    "- Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e961f9",
   "metadata": {
    "id": "f2e961f9"
   },
   "source": [
    "## Objective: \n",
    "- The Classification goal is to predict “heart disease” in a person with regards to different factors given. \n",
    "\n",
    "## Context:\n",
    "- Heart disease is one of the leading causes of death for people of most races in the US. At least 1 of 3 key risk factors for heart disease: high blood pressure, high cholesterol, and smoking. \n",
    "- Detecting and preventing the factors that have the greatest impact on heart disease is very important in healthcare. Machine learning methods may detect \"patterns\" from the data and can predict whether a patient is suffering from any heart disease or not..\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "#### Source: https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease?datasetId=1936563&sortBy=voteCount\n",
    "Originally, the dataset come from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of U.S. residents. \n",
    "\n",
    "This dataset consists of eighteen columns\n",
    "- HeartDisease: Respondents that have ever reported having coronary heart disease (CHD) or myocardial infarction (MI)\n",
    "- BMI: Body Mass Index (BMI)\n",
    "- Smoking: smoked at least 100 cigarettes in your entire life\n",
    "- AlcoholDrinking: Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week\n",
    "- Stroke:Ever had a stroke?\n",
    "- PhysicalHealth: physical health, which includes physical illness and injury\n",
    "- MentalHealth: for how many days during the past 30 days was your mental health not good?\n",
    "- DiffWalking: Do you have serious difficulty walking or climbing stairs?\n",
    "- Sex: male or female?\n",
    "- AgeCategory: Fourteen-level age category\n",
    "- Race: Imputed race/ethnicity value\n",
    "- Diabetic: diabetes?\n",
    "- PhysicalActivity: Adults who reported doing physical activity or exercise during the past 30 days other than their regular job\n",
    "- GenHealth: Would you say that in general your health is good, fine or excellent?\n",
    "- SleepTime: On average, how many hours of sleep do you get in a 24-hour period?\n",
    "- Asthma: you had asthma?\n",
    "- KidneyDisease: Not including kidney stones, bladder infection or incontinence, were you ever told you had kidney disease?\n",
    "- SkinCancer: Ever had skin cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8617014",
   "metadata": {
    "id": "f8617014"
   },
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b0b6ab",
   "metadata": {
    "id": "e0b0b6ab"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1a778",
   "metadata": {
    "id": "8fe1a778"
   },
   "source": [
    "### 2. Load the dataset and display a sample of five rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "l9XqZkTqVi4_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1655549650830,
     "user": {
      "displayName": "Ranjitha Prasad",
      "userId": "10570177482505539876"
     },
     "user_tz": -330
    },
    "id": "l9XqZkTqVi4_",
    "outputId": "06e1dda9-5e04-4067-ead3-78de3e61da93"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'heart_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheart_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'heart_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('heart_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65d16b",
   "metadata": {
    "id": "7d65d16b"
   },
   "source": [
    "### 3. Check the shape of the data (number of rows and columns). Check the general information about the dataframe using the .info() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c36e6",
   "metadata": {
    "id": "844c36e6",
    "outputId": "177c8837-df49-4c3c-97ca-8ee85861ba89"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59b172",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1655549707657,
     "user": {
      "displayName": "Ranjitha Prasad",
      "userId": "10570177482505539876"
     },
     "user_tz": -330
    },
    "id": "5e59b172",
    "outputId": "2a07cb32-76f9-451d-efd0-28104ad1d807"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4be9a5",
   "metadata": {
    "id": "9d4be9a5"
   },
   "source": [
    "- The output shows that we have around 319795 entries with 18 columns. \n",
    "- We have 14 object type data and 4 float type data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052145a",
   "metadata": {
    "id": "1052145a"
   },
   "source": [
    "### 4. Check the statistical summary of the dataset and write your inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df66600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1655549751344,
     "user": {
      "displayName": "Ranjitha Prasad",
      "userId": "10570177482505539876"
     },
     "user_tz": -330
    },
    "id": "5df66600",
    "outputId": "4efd27ec-9dd4-46c2-b6b8-488f0c7b62fb"
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100fc51",
   "metadata": {
    "id": "9100fc51",
    "outputId": "a1f7983f-16c1-4c0b-aff6-d00b46d8c653"
   },
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2fdc1",
   "metadata": {
    "id": "46e2fdc1"
   },
   "source": [
    "### 5. Check the percentage of missing values in each column of the data frame. Drop the missing values if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f6435",
   "metadata": {
    "id": "209f6435",
    "outputId": "8167a227-d59d-4633-ff0f-d6cb7ce3f6ff"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a523216",
   "metadata": {
    "id": "3a523216"
   },
   "source": [
    "### 6. Check if there are any duplicate rows. If any drop them and check the shape of the dataframe after dropping duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0869572",
   "metadata": {
    "id": "c0869572",
    "outputId": "f9f2bf79-00d5-4438-ab0b-a12ab758dc56"
   },
   "outputs": [],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcd7e9",
   "metadata": {
    "id": "11bcd7e9"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d5277",
   "metadata": {
    "id": "999d5277",
    "outputId": "838d11e0-109d-4d7f-abad-54b02b240e8d"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0eccca",
   "metadata": {
    "id": "5d0eccca"
   },
   "source": [
    "### 7. Check the distribution of the target variable (i.e. 'HeartDisease') and write your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8790409",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1655446442181,
     "user": {
      "displayName": "V. Arun Kumar",
      "userId": "02991517788843717529"
     },
     "user_tz": -330
    },
    "id": "a8790409",
    "outputId": "f65a2f0e-fb50-4836-c5d4-e47f621dcc8c"
   },
   "outputs": [],
   "source": [
    "df['HeartDisease'].value_counts().plot(kind='pie',autopct='%1.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca20d0",
   "metadata": {
    "id": "20ca20d0"
   },
   "source": [
    "### 8. Visualize the distribution of the target column 'heart disease' with respect to various categorical features and write your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e41b9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1655550161776,
     "user": {
      "displayName": "Ranjitha Prasad",
      "userId": "10570177482505539876"
     },
     "user_tz": -330
    },
    "id": "a2e41b9a",
    "outputId": "f07538fb-a05c-4dbd-e8c8-eb1c207751ed"
   },
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include=[np.object])\n",
    "categorical_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4d3ab",
   "metadata": {
    "id": "48a4d3ab"
   },
   "source": [
    "##### Let's look at the distribution of the number of people with heart disease from various factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea82c0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "executionInfo": {
     "elapsed": 8212,
     "status": "ok",
     "timestamp": 1655550181866,
     "user": {
      "displayName": "Ranjitha Prasad",
      "userId": "10570177482505539876"
     },
     "user_tz": -330
    },
    "id": "dea82c0c",
    "outputId": "8ef49295-2752-4a84-cd90-c03e7ec9f65a"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize = (30,25))\n",
    "for feature in categorical_features:\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.countplot(x = feature,hue = 'HeartDisease' , data = df)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a9878",
   "metadata": {
    "id": "1d2a9878"
   },
   "source": [
    "### 9. Check the unique categories in the column 'Diabetic'. Replace 'Yes (during pregnancy)' as 'Yes' and 'No, borderline diabetes' as 'No'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e88d2",
   "metadata": {
    "id": "805e88d2",
    "outputId": "c95c4bfd-3fee-4dac-82a2-1a8a6ccdc874"
   },
   "outputs": [],
   "source": [
    "df['Diabetic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af12c95",
   "metadata": {
    "id": "3af12c95"
   },
   "outputs": [],
   "source": [
    "df['Diabetic'] = df['Diabetic'].replace({'Yes (during pregnancy)':'Yes','No, borderline diabetes':'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7cdcd",
   "metadata": {
    "id": "abe7cdcd",
    "outputId": "d476fdd3-1d02-4e76-b5cb-3ca2b4a44310"
   },
   "outputs": [],
   "source": [
    "df['Diabetic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731fc61",
   "metadata": {
    "id": "a731fc61"
   },
   "source": [
    "### 10. For the target column 'HeartDiease', Replace 'No' as 0 and 'Yes' as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d122c9",
   "metadata": {
    "id": "61d122c9"
   },
   "outputs": [],
   "source": [
    "df['HeartDisease'] = df['HeartDisease'].replace({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044e1f0",
   "metadata": {
    "id": "6044e1f0",
    "outputId": "ccbf1348-a561-4a90-ea74-680541e4964f"
   },
   "outputs": [],
   "source": [
    "df['HeartDisease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06850aa",
   "metadata": {
    "id": "d06850aa"
   },
   "source": [
    "### 11. Label Encode the columns \"AgeCategory\", \"Race\", and \"GenHealth\". Encode the rest of the columns using dummy encoding approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525986e3",
   "metadata": {
    "id": "525986e3"
   },
   "outputs": [],
   "source": [
    "object_type_variables = [i for i in df[['AgeCategory','Race','GenHealth']] if df.dtypes[i] == object]\n",
    "object_type_variables \n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "def encoder(df):\n",
    "    for i in object_type_variables:\n",
    "        q = le.fit_transform(df[i].astype(str))  \n",
    "        df[i] = q                               \n",
    "        df[i] = df[i].astype(int)\n",
    "encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b1393",
   "metadata": {
    "id": "9a7b1393"
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0849daf",
   "metadata": {
    "id": "a0849daf",
    "outputId": "ab04a583-be8d-4dd4-8bdb-823a515d6fd0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991aa01",
   "metadata": {
    "id": "e991aa01"
   },
   "source": [
    "### 12. Store the target column (i.e.'HeartDisease') in the y variable and the rest of the columns in the X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977652b9",
   "metadata": {
    "id": "977652b9"
   },
   "outputs": [],
   "source": [
    "X = df.drop('HeartDisease',axis=1)\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f97c6f",
   "metadata": {
    "id": "32f97c6f"
   },
   "source": [
    "### 13. Split the dataset into two parts (i.e. 70% train and 30% test) and print the shape of the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be616a7",
   "metadata": {
    "id": "7be616a7",
    "outputId": "435d6812-25f1-474e-c7e8-da5974b84664"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea8dd55",
   "metadata": {
    "id": "8ea8dd55"
   },
   "source": [
    "### 14. Standardize the numerical columns using Standard Scalar approach for both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb45096",
   "metadata": {
    "id": "cbb45096"
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train.iloc[:,:7] = ss.fit_transform(X_train.iloc[:,:7])\n",
    "X_test.iloc[:,:7] = ss.transform(X_test.iloc[:,:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25bbdf",
   "metadata": {
    "id": "8f25bbdf",
    "outputId": "718b7df6-a30f-46a4-d2c0-7166a21ebf65"
   },
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57386022",
   "metadata": {
    "id": "57386022",
    "outputId": "b885ec05-3648-4750-9702-86e85fe8c73f"
   },
   "outputs": [],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb30aab",
   "metadata": {
    "id": "bdb30aab"
   },
   "source": [
    "### 15. Write a function.\n",
    "- i) Which can take the model and data as inputs.\n",
    "- ii) Fits the model with the train data.\n",
    "- iii) Makes predictions on the test set.\n",
    "- iv) Returns the Accuracy Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6138f02",
   "metadata": {
    "id": "b6138f02"
   },
   "outputs": [],
   "source": [
    "def fit_n_print(model, X_train, X_test, y_train, y_test):  # take the model, and data as inputs\n",
    "\n",
    "    model.fit(X_train, y_train)   # fits the model with the train data\n",
    "\n",
    "    pred = model.predict(X_test)  # makes predictions on the test set\n",
    "\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "                   \n",
    "    return accuracy  # return all the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b277c",
   "metadata": {
    "id": "862b277c"
   },
   "source": [
    "### 16. Use the function and train a Logistic regression, KNN, Naive Bayes, Decision tree, Random Forest, Adaboost, GradientBoost, and Stacked Classifier models and make predictions on test data and evaluate the models, compare and write your conclusions and steps to be taken in future in order to improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556977d",
   "metadata": {
    "id": "6556977d"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "adb = AdaBoostClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "estimators = [('rf', rf),('knn', knn), ('gb', gb), ('adb', adb)]\n",
    "sc = StackingClassifier(estimators=estimators, final_estimator=rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8addbbbd",
   "metadata": {
    "id": "8addbbbd"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns = ['Accuracy'])\n",
    "\n",
    "for model, model_name in zip([lr, nb, knn, dt, rf, adb, gb, sc], \n",
    "                             ['Logistic Regression','Naive Bayes','KNN','Decision tree', \n",
    "                              'Random Forest', 'Ada Boost', 'Gradient Boost', 'Stacking']):\n",
    "    \n",
    "    result.loc[model_name] = fit_n_print(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90db9ec",
   "metadata": {
    "id": "f90db9ec",
    "outputId": "a661172f-8b11-4c0e-c0c9-9a1638283234"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "f8617014",
    "8fe1a778",
    "7d65d16b",
    "1052145a",
    "46e2fdc1",
    "3a523216",
    "5d0eccca",
    "20ca20d0",
    "1d2a9878",
    "a731fc61",
    "d06850aa",
    "e991aa01",
    "32f97c6f",
    "8ea8dd55",
    "bdb30aab",
    "862b277c"
   ],
   "name": "Supervised Learning - Lab Session - Sample Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
